{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "061ed4b0",
   "metadata": {},
   "source": [
    "# LLM-human collaborative annotation \n",
    "This notebook illustrates the integration of Large Language Models (LLMs) into the MEGAnno framework. In this framework, LLMs serve as annotators, and human verification is used to validate the annotation results. Initially, we demonstrate this integration with OpenAI's GPT models and completion APIs.\n",
    "\n",
    "Users can register agents by specifying model configurations and prompt configurations, select a subset, and run the job. MEGAnno takes care of the following tasks:\n",
    "\n",
    "* Interfacing with OpenAI and handling errors.\n",
    "* Executing LLM models and persisting the results.\n",
    "* Providing flexible search capabilities to support human verification and downstream applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48743562",
   "metadata": {},
   "source": [
    "# 1. Setup\n",
    "## 1.1 Authentication and MEGAnno project connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb84fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meganno_client import Authentication\n",
    "auth = Authentication(project=\"eacl_demo\", token=<megagon_distributed_token>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de013990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meganno_client import Service\n",
    "\n",
    "# or use own auth/token\n",
    "demo = Service(project=\"eacl_demo\", auth=auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c3f29f",
   "metadata": {},
   "source": [
    "## 1.2 Review labeling schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c6b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### review schema\n",
    "import pprint\n",
    "schema = demo.get_schemas().value(active=True)\n",
    "pprint.pprint(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055afb69",
   "metadata": {},
   "source": [
    "# 2. LLM Annotation\n",
    "## 2.1 Config model and prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869c3ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"temperature\": 0,\n",
    "    \"n\": 1,\n",
    "    \"logprobs\": True,\n",
    "    \"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28af3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name = \"sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7760f126",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from meganno_client.prompt import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    label_schema=schema[0][\"schemas\"][\"label_schema\"], label_names=[label_name]\n",
    ")\n",
    "prompt_template.preview(\n",
    "    records=[\"[sample input]\", \"Megagon Labs is located in Mountain View.\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a8e71d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e4a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template.get_template()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a12774b",
   "metadata": {},
   "source": [
    "## 2.2 Register an agent with service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c818fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meganno_client.controller import Controller\n",
    "\n",
    "controller = Controller(demo, auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6686c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_uuid = controller.create_agent(\n",
    "    model_config, prompt_template, provider_api=\"openai:chat\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bece3a62",
   "metadata": {},
   "source": [
    "## 2.3 Run an LLM annotation job on subsets\n",
    "**!Make sure OPENAI_API_KEY is set as an env var.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c35f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting subset to run the job with\n",
    "subset = demo.search(keyword=\"delay\", limit=4)\n",
    "subset.show({\"view\": \"table\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ec5c50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "job_uuid = controller.run_job(agent_uuid, subset, label_name, label_meta_names=[\"conf\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d8835",
   "metadata": {},
   "source": [
    "## 2.4 List agents & jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ee9aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list agents\n",
    "controller.list_my_agents()\n",
    "# job_list = controller.list_jobs('agent_uuid', [agent_uuid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfd3c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter over agent properties and get jobs\n",
    "ret = controller.list_agents(provider_filter=\"openai\", show_job_list=True)\n",
    "job_list = [val for sublist in ret for val in sublist[\"job_list\"]]\n",
    "job_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168fa272",
   "metadata": {},
   "source": [
    "# Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11995d4",
   "metadata": {},
   "source": [
    "## 3.1 Verify annotations from a job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd78c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"job_id\": job_uuid,\n",
    "    \"label_metadata_condition\": {\n",
    "        \"label_name\": \"sentiment\",\n",
    "        \"name\": \"conf\",\n",
    "        \"operator\": \"<\",\n",
    "        \"value\": 0.99,\n",
    "    },\n",
    "    \"verification_condition\": {\n",
    "        \"label_name\": label_name,\n",
    "        \"search_mode\": \"ALL\",  # \"ALL\"|\"UNVERIFIED\"|\"VERIFIED\"\n",
    "    },\n",
    "}\n",
    "verf_subset = demo.search_by_job(**args)\n",
    "verf_subset.show({\"mode\": \"verifying\", \"label_meta_names\": [\"conf\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef193897",
   "metadata": {},
   "source": [
    "## 3.2 Retrieve Verification Annotations\n",
    "The current version supports only programmatic retrieval of previous verifications, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6374ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# further filter by type of verification(CONFIRMS|CORRECTS)\n",
    "# CONFIMS:  where the verification confirms the original label\n",
    "# CORRECTS: where the verification is different from the original label\n",
    "verf_subset.get_verification_annotations(\n",
    "    label_name=\"sentiment\",\n",
    "    label_level=\"record\",\n",
    "    annotator=job_uuid,\n",
    "    verified_status=\"CORRECTS\",  # CONFIRMS|CORRECTS\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
